{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Using cached kagglehub-0.3.7-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting model-signing (from kagglehub)\n",
      "  Using cached model_signing-0.2.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from kagglehub) (4.65.0)\n",
      "Requirement already satisfied: cryptography in /opt/anaconda3/lib/python3.11/site-packages (from model-signing->kagglehub) (42.0.5)\n",
      "Collecting in-toto-attestation (from model-signing->kagglehub)\n",
      "  Using cached in_toto_attestation-0.9.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sigstore (from model-signing->kagglehub)\n",
      "  Using cached sigstore-3.6.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from model-signing->kagglehub) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.11/site-packages (from cryptography->model-signing->kagglehub) (1.16.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.11/site-packages (from in-toto-attestation->model-signing->kagglehub) (3.20.3)\n",
      "Collecting id>=1.1.0 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached id-1.5.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1~=0.6 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from sigstore->model-signing->kagglehub) (2.5.3)\n",
      "Requirement already satisfied: pyjwt>=2.1 in /opt/anaconda3/lib/python3.11/site-packages (from sigstore->model-signing->kagglehub) (2.4.0)\n",
      "Requirement already satisfied: pyOpenSSL>=23.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from sigstore->model-signing->kagglehub) (24.0.0)\n",
      "Requirement already satisfied: rich~=13.0 in /opt/anaconda3/lib/python3.11/site-packages (from sigstore->model-signing->kagglehub) (13.3.5)\n",
      "Collecting rfc8785~=0.1.2 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached rfc8785-0.1.4-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rfc3161-client~=0.1.2 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached rfc3161_client-0.1.2-cp39-abi3-macosx_10_12_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting sigstore-protobuf-specs==0.3.2 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached sigstore_protobuf_specs-0.3.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sigstore-rekor-types==0.0.18 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached sigstore_rekor_types-0.0.18-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tuf~=5.0 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached tuf-5.1.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting platformdirs~=4.2 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting betterproto==2.0.0b6 (from sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub)\n",
      "  Using cached betterproto-2.0.0b6-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting grpclib<0.5.0,>=0.4.1 (from betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub)\n",
      "  Using cached grpclib-0.4.7.tar.gz (61 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0,>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.11/site-packages (from cffi>=1.12->cryptography->model-signing->kagglehub) (2.21)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=2->sigstore->model-signing->kagglehub) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=2->sigstore->model-signing->kagglehub) (2.14.6)\n",
      "INFO: pip is looking at multiple versions of rfc3161-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyOpenSSL>=23.0.0 (from sigstore->model-signing->kagglehub)\n",
      "  Using cached pyOpenSSL-25.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting cryptography (from model-signing->kagglehub)\n",
      "  Using cached cryptography-44.0.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich~=13.0->sigstore->model-signing->kagglehub) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich~=13.0->sigstore->model-signing->kagglehub) (2.15.1)\n",
      "Collecting securesystemslib~=1.0 (from tuf~=5.0->sigstore->model-signing->kagglehub)\n",
      "  Using cached securesystemslib-1.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich~=13.0->sigstore->model-signing->kagglehub) (0.1.0)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub)\n",
      "  Using cached email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting h2<5,>=3.1.0 (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub)\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: multidict in /opt/anaconda3/lib/python3.11/site-packages (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (6.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil<3.0,>=2.8->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (1.16.0)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Using cached kagglehub-0.3.7-py3-none-any.whl (54 kB)\n",
      "Using cached model_signing-0.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached in_toto_attestation-0.9.3-py3-none-any.whl (13 kB)\n",
      "Using cached sigstore-3.6.1-py3-none-any.whl (99 kB)\n",
      "Using cached sigstore_protobuf_specs-0.3.2-py3-none-any.whl (24 kB)\n",
      "Using cached sigstore_rekor_types-0.0.18-py3-none-any.whl (20 kB)\n",
      "Using cached betterproto-2.0.0b6-py3-none-any.whl (64 kB)\n",
      "Using cached id-1.5.0-py3-none-any.whl (13 kB)\n",
      "Using cached platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyOpenSSL-25.0.0-py3-none-any.whl (56 kB)\n",
      "Using cached rfc3161_client-0.1.2-cp39-abi3-macosx_10_12_x86_64.whl (450 kB)\n",
      "Using cached cryptography-44.0.0-cp39-abi3-macosx_10_9_universal2.whl (6.5 MB)\n",
      "Using cached rfc8785-0.1.4-py3-none-any.whl (9.2 kB)\n",
      "Using cached tuf-5.1.0-py3-none-any.whl (50 kB)\n",
      "Using cached securesystemslib-1.2.0-py3-none-any.whl (870 kB)\n",
      "Using cached email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: grpclib\n",
      "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpclib: filename=grpclib-0.4.7-py3-none-any.whl size=76229 sha256=c50eb77ff612e889cce42f2dcd7e2206f2845af0eb09d5a8764bcfb9ef108b79\n",
      "  Stored in directory: /Users/catalinamalinowski/Library/Caches/pip/wheels/1a/6e/f8/47a179a8cf84417e94206ee7bdee3cc4219a011e6ca1973eb0\n",
      "Successfully built grpclib\n",
      "Installing collected packages: securesystemslib, rfc8785, pyasn1, platformdirs, in-toto-attestation, hyperframe, hpack, dnspython, tuf, id, h2, email-validator, cryptography, rfc3161-client, pyOpenSSL, grpclib, sigstore-rekor-types, betterproto, sigstore-protobuf-specs, sigstore, model-signing, kagglehub\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.4.8\n",
      "    Uninstalling pyasn1-0.4.8:\n",
      "      Successfully uninstalled pyasn1-0.4.8\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 3.10.0\n",
      "    Uninstalling platformdirs-3.10.0:\n",
      "      Successfully uninstalled platformdirs-3.10.0\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 42.0.5\n",
      "    Uninstalling cryptography-42.0.5:\n",
      "      Successfully uninstalled cryptography-42.0.5\n",
      "  Attempting uninstall: pyOpenSSL\n",
      "    Found existing installation: pyOpenSSL 24.0.0\n",
      "    Uninstalling pyOpenSSL-24.0.0:\n",
      "      Successfully uninstalled pyOpenSSL-24.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyasn1-modules 0.2.8 requires pyasn1<0.5.0,>=0.4.6, but you have pyasn1 0.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed betterproto-2.0.0b6 cryptography-44.0.0 dnspython-2.7.0 email-validator-2.2.0 grpclib-0.4.7 h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 id-1.5.0 in-toto-attestation-0.9.3 kagglehub-0.3.7 model-signing-0.2.0 platformdirs-4.3.6 pyOpenSSL-25.0.0 pyasn1-0.6.1 rfc3161-client-0.1.2 rfc8785-0.1.4 securesystemslib-1.2.0 sigstore-3.6.1 sigstore-protobuf-specs-0.3.2 sigstore-rekor-types-0.0.18 tuf-5.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/catalinamalinowski/.cache/kagglehub/datasets/vincentvaseghi/us-cities-housing-market-data/versions/33\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "# Download latest version\n",
    "\n",
    "path = kagglehub.dataset_download(\"vincentvaseghi/us-cities-housing-market-data\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/catalinamalinowski/.cache/kagglehub/datasets/vincentvaseghi/us-cities-housing-market-data/versions/33\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vincentvaseghi/us-cities-housing-market-data\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city_market_tracker.tsv000']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"/Users/catalinamalinowski/.cache/kagglehub/datasets/vincentvaseghi/us-cities-housing-market-data/versions/33\"\n",
    "print(os.listdir(directory_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/catalinamalinowski/.cache/kagglehub/datasets/vincentvaseghi/us-cities-housing-market-data/versions/33/city_market_tracker.tsv000\"  # Replace with actual file name\n",
    "import pandas as pd\n",
    "df = pd.read_csv(file_path, delimiter=\"\\t\")  # Ensure the correct delimiter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['period_begin', 'period_end', 'period_duration', 'region_type', 'region_type_id', 'table_id', 'is_seasonally_adjusted', 'region', 'city', 'state', 'state_code', 'property_type', 'property_type_id', 'median_sale_price', 'median_sale_price_mom', 'median_sale_price_yoy', 'median_list_price', 'median_list_price_mom', 'median_list_price_yoy', 'median_ppsf', 'median_ppsf_mom', 'median_ppsf_yoy', 'median_list_ppsf', 'median_list_ppsf_mom', 'median_list_ppsf_yoy', 'homes_sold', 'homes_sold_mom', 'homes_sold_yoy', 'pending_sales', 'pending_sales_mom', 'pending_sales_yoy', 'new_listings', 'new_listings_mom', 'new_listings_yoy', 'inventory', 'inventory_mom', 'inventory_yoy', 'months_of_supply', 'months_of_supply_mom', 'months_of_supply_yoy', 'median_dom', 'median_dom_mom', 'median_dom_yoy', 'avg_sale_to_list', 'avg_sale_to_list_mom', 'avg_sale_to_list_yoy', 'sold_above_list', 'sold_above_list_mom', 'sold_above_list_yoy', 'price_drops', 'price_drops_mom', 'price_drops_yoy', 'off_market_in_two_weeks', 'off_market_in_two_weeks_mom', 'off_market_in_two_weeks_yoy', 'parent_metro_region', 'parent_metro_region_metro_code', 'last_updated']\n"
     ]
    }
   ],
   "source": [
    "# Get all column names\n",
    "columns = df.columns.tolist()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period_begin                       object\n",
      "period_end                         object\n",
      "period_duration                     int64\n",
      "region_type                        object\n",
      "region_type_id                      int64\n",
      "table_id                            int64\n",
      "is_seasonally_adjusted             object\n",
      "region                             object\n",
      "city                               object\n",
      "state                              object\n",
      "state_code                         object\n",
      "property_type                      object\n",
      "property_type_id                    int64\n",
      "median_sale_price                 float64\n",
      "median_sale_price_yoy             float64\n",
      "median_list_price                 float64\n",
      "median_list_price_yoy             float64\n",
      "median_ppsf                       float64\n",
      "median_ppsf_yoy                   float64\n",
      "median_list_ppsf                  float64\n",
      "median_list_ppsf_yoy              float64\n",
      "homes_sold                        float64\n",
      "homes_sold_yoy                    float64\n",
      "pending_sales                     float64\n",
      "pending_sales_yoy                 float64\n",
      "new_listings                      float64\n",
      "new_listings_yoy                  float64\n",
      "inventory                         float64\n",
      "inventory_yoy                     float64\n",
      "months_of_supply                  float64\n",
      "months_of_supply_yoy              float64\n",
      "median_dom                        float64\n",
      "median_dom_yoy                    float64\n",
      "avg_sale_to_list                  float64\n",
      "avg_sale_to_list_yoy              float64\n",
      "sold_above_list                   float64\n",
      "sold_above_list_yoy               float64\n",
      "price_drops                       float64\n",
      "price_drops_yoy                   float64\n",
      "off_market_in_two_weeks           float64\n",
      "off_market_in_two_weeks_yoy       float64\n",
      "parent_metro_region                object\n",
      "parent_metro_region_metro_code      int64\n",
      "last_updated                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['median_sale_price_mom', 'median_list_price_mom', 'median_ppsf_mom', 'median_list_ppsf_mom', 'homes_sold_mom', 'pending_sales_mom', 'new_listings_mom', 'inventory_mom', 'months_of_supply_mom', 'median_dom_mom', 'avg_sale_to_list_mom', 'sold_above_list_mom', 'price_drops_mom', 'off_market_in_two_weeks_mom'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop multiple columns -- we are not interested in looking at month-to-month data and want to make this a more reasonable sized data set for this project.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# We are dropping all month-to-month variables which include: median_sale_price_mom, price_drops_mom, off_market_in_two_weeks_mom\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_sale_price_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_list_price_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_ppsf_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_list_ppsf_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhomes_sold_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m,\\\n\u001b[1;32m      4\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpending_sales_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_listings_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minventory_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonths_of_supply_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_dom_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m,\\\n\u001b[1;32m      5\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_sale_to_list_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msold_above_list_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_drops_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff_market_in_two_weeks_mom\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#check size of file after dropping variables\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mmemory_usage(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5433\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5569\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5570\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5571\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5572\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5573\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5574\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5575\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5576\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4785\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4827\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4825\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4827\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4828\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4830\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['median_sale_price_mom', 'median_list_price_mom', 'median_ppsf_mom', 'median_list_ppsf_mom', 'homes_sold_mom', 'pending_sales_mom', 'new_listings_mom', 'inventory_mom', 'months_of_supply_mom', 'median_dom_mom', 'avg_sale_to_list_mom', 'sold_above_list_mom', 'price_drops_mom', 'off_market_in_two_weeks_mom'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop multiple columns -- we are not interested in looking at month-to-month data and want to make this a more reasonable sized data set for this project.\n",
    "# We are dropping all month-to-month variables which include: median_sale_price_mom, price_drops_mom, off_market_in_two_weeks_mom\n",
    "df = df.drop(columns=[\"median_sale_price_mom\", \"median_list_price_mom\", \"median_ppsf_mom\", \"median_list_ppsf_mom\", \"homes_sold_mom\",\\\n",
    "                      \"pending_sales_mom\", \"new_listings_mom\", \"inventory_mom\", \"months_of_supply_mom\", \"median_dom_mom\",\\\n",
    "                      \"avg_sale_to_list_mom\", \"sold_above_list_mom\", \"price_drops_mom\", \"off_market_in_two_weeks_mom\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5714784649 bytes\n"
     ]
    }
   ],
   "source": [
    "#check size of file after dropping variables\n",
    "print(df.memory_usage(deep=True).sum(), \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['period_begin', 'period_end', 'period_duration', 'region_type', 'region_type_id', 'table_id', 'is_seasonally_adjusted', 'region', 'city', 'state', 'state_code', 'property_type', 'property_type_id', 'median_sale_price', 'median_sale_price_yoy', 'median_list_price', 'median_list_price_yoy', 'median_ppsf', 'median_ppsf_yoy', 'median_list_ppsf', 'median_list_ppsf_yoy', 'homes_sold', 'homes_sold_yoy', 'pending_sales', 'pending_sales_yoy', 'new_listings', 'new_listings_yoy', 'inventory', 'inventory_yoy', 'months_of_supply', 'months_of_supply_yoy', 'median_dom', 'median_dom_yoy', 'avg_sale_to_list', 'avg_sale_to_list_yoy', 'sold_above_list', 'sold_above_list_yoy', 'price_drops', 'price_drops_yoy', 'off_market_in_two_weeks', 'off_market_in_two_weeks_yoy', 'parent_metro_region', 'parent_metro_region_metro_code', 'last_updated']\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns.tolist()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'California': 455064, 'New York': 426373, 'Pennsylvania': 395178, 'Florida': 352236, 'Illinois': 277414, 'Ohio': 264781, 'Texas': 262314, 'Massachusetts': 231488, 'New Jersey': 225027, 'Washington': 168126, 'Maryland': 162180, 'North Carolina': 158418, 'Michigan': 158362, 'Virginia': 141910, 'Minnesota': 134545, 'Wisconsin': 128741, 'Indiana': 117504, 'Georgia': 114029, 'Missouri': 110792, 'Colorado': 100674, 'Oregon': 96160, 'Alabama': 84992, 'Tennessee': 82852, 'South Carolina': 75774, 'Kentucky': 74959, 'Arizona': 68796, 'Iowa': 68768, 'Utah': 68541, 'Connecticut': 67868, 'Louisiana': 64177, 'Oklahoma': 56279, 'Arkansas': 49955, 'Kansas': 48523, 'Hawaii': 46783, 'Idaho': 34720, 'New Hampshire': 34110, 'Mississippi': 32578, 'Rhode Island': 27768, 'West Virginia': 26733, 'Nebraska': 26066, 'New Mexico': 25492, 'Nevada': 24872, 'Maine': 24812, 'Vermont': 22858, 'Montana': 20995, 'South Dakota': 19324, 'Delaware': 16122, 'Alaska': 12854, 'Wyoming': 10506, 'North Dakota': 7869, 'Columbia': 780}\n"
     ]
    }
   ],
   "source": [
    "value_dict = df[\"state\"].value_counts().to_dict()\n",
    "print(value_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert period_begin to datetime\n",
    "df['period_begin'] = pd.to_datetime(df['period_begin'])\n",
    "\n",
    "#Filter from 2020-2025\n",
    "five_yr_df = df[df['period_begin'] >= '2020-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        period_begin  period_end  period_duration region_type  region_type_id  \\\n",
      "5         2024-04-01  2024-04-30               30       place               6   \n",
      "12        2024-05-01  2024-05-31               30       place               6   \n",
      "25        2024-07-01  2024-07-31               30       place               6   \n",
      "47        2021-04-01  2021-04-30               30       place               6   \n",
      "83        2022-11-01  2022-11-30               30       place               6   \n",
      "...              ...         ...              ...         ...             ...   \n",
      "5707967   2023-10-01  2023-10-31               30       place               6   \n",
      "5707969   2024-04-01  2024-04-30               30       place               6   \n",
      "5708033   2023-05-01  2023-05-31               30       place               6   \n",
      "5708034   2024-04-01  2024-04-30               30       place               6   \n",
      "5708039   2024-08-01  2024-08-31               30       place               6   \n",
      "\n",
      "         table_id is_seasonally_adjusted                    region  \\\n",
      "5            8805                      f         Holiday Lakes, TX   \n",
      "12          10173                      f           Krugerville, TX   \n",
      "25            475                      f                 Alice, TX   \n",
      "47            475                      f                 Alice, TX   \n",
      "83          19395                      f               Watauga, TX   \n",
      "...           ...                    ...                       ...   \n",
      "5707967      2714                      f       Carolina Shores, NC   \n",
      "5707969     23177                      f      Gloucester Point, VA   \n",
      "5708033     13493                      f  North Richland Hills, TX   \n",
      "5708034      9223                      f            Kure Beach, NC   \n",
      "5708039     18307                      f            Weddington, NC   \n",
      "\n",
      "                         city           state  ... avg_sale_to_list_yoy  \\\n",
      "5               Holiday Lakes           Texas  ...                  NaN   \n",
      "12                Krugerville           Texas  ...            -0.005388   \n",
      "25                      Alice           Texas  ...            -0.099491   \n",
      "47                      Alice           Texas  ...             0.059018   \n",
      "83                    Watauga           Texas  ...            -0.043691   \n",
      "...                       ...             ...  ...                  ...   \n",
      "5707967       Carolina Shores  North Carolina  ...             0.000709   \n",
      "5707969      Gloucester Point        Virginia  ...            -0.028038   \n",
      "5708033  North Richland Hills           Texas  ...            -0.050739   \n",
      "5708034            Kure Beach  North Carolina  ...            -0.026532   \n",
      "5708039            Weddington  North Carolina  ...            -0.031425   \n",
      "\n",
      "        sold_above_list  sold_above_list_yoy  price_drops  price_drops_yoy  \\\n",
      "5              0.000000                  NaN     0.333333              NaN   \n",
      "12             0.166667             0.023810     0.066667        -0.361905   \n",
      "25             0.090909            -0.051948     0.105263        -0.052632   \n",
      "47             0.333333             0.333333          NaN              NaN   \n",
      "83             0.222222            -0.384921     0.393939         0.240093   \n",
      "...                 ...                  ...          ...              ...   \n",
      "5707967        0.142857             0.142857     0.357143         0.175325   \n",
      "5707969        0.666667             0.333333     1.000000              NaN   \n",
      "5708033        0.444444            -0.277778     0.276423        -0.019874   \n",
      "5708034        0.000000            -0.250000     0.238095         0.007326   \n",
      "5708039        0.125000            -0.284091     0.423077         0.181698   \n",
      "\n",
      "         off_market_in_two_weeks  off_market_in_two_weeks_yoy  \\\n",
      "5                       0.000000                          NaN   \n",
      "12                      0.500000                     0.333333   \n",
      "25                      0.333333                     0.102564   \n",
      "47                      0.312500                     0.312500   \n",
      "83                      0.272727                    -0.314229   \n",
      "...                          ...                          ...   \n",
      "5707967                 0.000000                    -0.750000   \n",
      "5707969                      NaN                          NaN   \n",
      "5708033                 0.731343                    -0.006030   \n",
      "5708034                 0.454545                    -0.259740   \n",
      "5708039                 0.444444                     0.096618   \n",
      "\n",
      "         parent_metro_region  parent_metro_region_metro_code  \\\n",
      "5                Houston, TX                           26420   \n",
      "12                Dallas, TX                           19124   \n",
      "25                 Alice, TX                           10860   \n",
      "47                 Alice, TX                           10860   \n",
      "83            Fort Worth, TX                           23104   \n",
      "...                      ...                             ...   \n",
      "5707967     Myrtle Beach, SC                           34820   \n",
      "5707969   Virginia Beach, VA                           47260   \n",
      "5708033       Fort Worth, TX                           23104   \n",
      "5708034       Wilmington, NC                           48900   \n",
      "5708039        Charlotte, NC                           16740   \n",
      "\n",
      "                last_updated  \n",
      "5        2025-01-13 14:16:48  \n",
      "12       2025-01-13 14:16:48  \n",
      "25       2025-01-13 14:16:48  \n",
      "47       2025-01-13 14:16:48  \n",
      "83       2025-01-13 14:16:48  \n",
      "...                      ...  \n",
      "5707967  2025-01-13 14:16:48  \n",
      "5707969  2025-01-13 14:16:48  \n",
      "5708033  2025-01-13 14:16:48  \n",
      "5708034  2025-01-13 14:16:48  \n",
      "5708039  2025-01-13 14:16:48  \n",
      "\n",
      "[238492 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "#For scope of the project, we are interested in only looking at Virginia, Texas, and North Carolina.\n",
    "# Define the states to keep\n",
    "states_to_keep = ['Texas', 'Virginia', 'North Carolina']\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = five_yr_df[five_yr_df['state'].isin(states_to_keep)]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226449586 bytes\n"
     ]
    }
   ],
   "source": [
    "#check size of file after dropping variables\n",
    "print(filtered_df.memory_usage(deep=True).sum(), \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv(\"TX,.tsv\", sep=\"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
